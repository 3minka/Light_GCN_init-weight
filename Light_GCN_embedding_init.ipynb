{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e42977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "user_num = 1000\n",
    "item_num = 4000\n",
    "latent_dim = 100\n",
    "\n",
    "embedding_user = nn.Embedding(num_embeddings=user_num, \n",
    "                               embedding_dim=latent_dim)\n",
    "embedding_item= nn.Embedding(num_embeddings=item_num, \n",
    "                               embedding_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e07420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fde93e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100]) torch.Size([4000, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3122,  1.3069,  0.6989,  ..., -0.1420,  0.2088,  0.7707],\n",
       "        [ 0.0591, -0.3785,  0.2088,  ..., -0.3123,  0.1208, -0.4062],\n",
       "        [ 0.1556,  0.2551,  0.4734,  ..., -0.1234,  0.2883,  1.0199],\n",
       "        ...,\n",
       "        [ 0.2718, -0.3941, -1.6571,  ..., -2.0296,  0.0838,  0.1728],\n",
       "        [ 2.0292,  0.0626, -1.2973,  ..., -1.8868, -1.9678, -0.7274],\n",
       "        [-0.1836, -0.4067,  0.1181,  ..., -1.3339,  0.8144,  0.1789]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding_user.weight.shape, embedding_item.weight.shape)\n",
    "embedding_user.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "252c7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight initalization\n",
    "embedding_user.weight = nn.init.normal_(embedding_user.weight, 0, 0.01) # (Tensor, mean, std)\n",
    "embedding_item.weight = nn.init.normal_(embedding_item.weight, 0, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "80f48b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_emb = embedding_user.weight\n",
    "items_emb = embedding_item.weight\n",
    "all_emb = torch.cat([users_emb, items_emb], dim=0)\n",
    "\n",
    "embs = [all_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a9c8cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f9c108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating adjacency matrix\n"
     ]
    }
   ],
   "source": [
    "rating_matrix = np.array(np.ones((4000,1000)))\n",
    "rating_matrix = sp.csr_matrix(rating_matrix)\n",
    "n_users, n_items = 4000, 1000\n",
    "\n",
    "print(\"generating adjacency matrix\")\n",
    "#s = time.time()\n",
    "adj_mat = sp.dok_matrix((n_users + n_items, n_users + n_items), dtype=np.float32) # 5000, 5000 # 1 \n",
    "adj_mat = adj_mat.tolil()                                                                      # 2\n",
    "R = rating_matrix.tolil()                                                                      # 3\n",
    "adj_mat[:n_users, n_users:] = R  # user와 item의 interection   n_users수의 행부터, 렬          # 4   \n",
    "adj_mat[n_users:, :n_users] = R.T  # user와 item의 interection   n_users수 이후의 행부터, 렬   # 5     \n",
    "adj_mat = adj_mat.todok()                                                                 # 6\n",
    "rowsum = np.array(adj_mat.sum(axis=1))      # sum(axis=1) 다 합친다.  (5000, 1)           # 7          \n",
    "d_inv = np.power(rowsum, -0.5).flatten()                                               # 8            \n",
    "d_inv[np.isinf(d_inv)] = 0.                                                            # 9\n",
    "d_mat = sp.diags(d_inv) # 합쳐진 embedding값을 diags로 5000, 5000으로 변환\n",
    "\n",
    "norm_adj = d_mat.dot(adj_mat)                                                            \n",
    "norm_adj = norm_adj.dot(d_mat)                                                            \n",
    "norm_adj = norm_adj.tocsr()                                                            \n",
    "#end = time.time()\n",
    "print(f\"costing {end - s}s, saved norm_mat...\")                                                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de867744",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([[1, 2, 3, 4], [11, 22, 33, 44], [111,222,333, 444], [1111,2222,3333,4444]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35e218ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    2,    3,    4],\n",
       "       [  11,   22,   33,   44],\n",
       "       [ 111,  222,  333,  444],\n",
       "       [1111, 2222, 3333, 4444]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9bf90fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4],\n",
       "       [33, 44]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[:2,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d53eeeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 111,  222],\n",
       "       [1111, 2222]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[2:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "39249037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_sp_mat_to_sp_tensor(X):\n",
    "    coo = X.tocoo().astype(np.float32)\n",
    "    row = torch.Tensor(coo.row).long()\n",
    "    col = torch.Tensor(coo.col).long()\n",
    "    index = torch.stack([row, col])\n",
    "    data = torch.FloatTensor(coo.data)\n",
    "    return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d5869933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do not split the matrix\n"
     ]
    }
   ],
   "source": [
    "Graph = _convert_sp_mat_to_sp_tensor(norm_adj)\n",
    "Graph = Graph.coalesce()#.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b6d0b9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    0,    0,  ..., 4999, 4999, 4999],\n",
       "                       [4000, 4001, 4002,  ..., 3997, 3998, 3999]]),\n",
       "       values=tensor([0.0005, 0.0005, 0.0005,  ..., 0.0005, 0.0005, 0.0005]),\n",
       "       size=(5000, 5000), nnz=8000000, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "323f42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "ego_emb = all_emb\n",
    "\n",
    "for k in range(num_layers):\n",
    "    all_emb = torch.sparse.mm(Graph, all_emb)\n",
    "    embs.append(all_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5e251632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5000, 100]), torch.Size([5000, 100]), torch.Size([5000, 100]), 3)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0].shape, embs[1].shape, embs[2].shape, len(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e35780d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0557e-03, -1.5728e-02, -9.4589e-03,  ...,  1.0007e-03,\n",
       "          3.2845e-04, -4.3579e-03],\n",
       "        [-5.6766e-03,  5.5115e-03, -1.8081e-03,  ...,  2.2576e-02,\n",
       "         -9.8114e-03, -2.6106e-04],\n",
       "        [-1.4560e-03,  2.7112e-04, -8.9938e-03,  ...,  9.3871e-03,\n",
       "          8.3590e-04,  9.1583e-04],\n",
       "        ...,\n",
       "        [-2.0350e-02, -4.8160e-03, -6.5907e-04,  ...,  4.9434e-03,\n",
       "          3.0143e-03, -1.9157e-02],\n",
       "        [-2.2831e-02,  1.9603e-02,  6.4267e-05,  ..., -1.5745e-03,\n",
       "         -1.2905e-02, -1.0184e-02],\n",
       "        [ 1.6405e-02,  1.5115e-03, -8.3334e-05,  ..., -9.0978e-03,\n",
       "         -2.9270e-03, -6.0976e-04]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4e7ade8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.stack(embs, dim=1)\n",
    "lightgcn_out = torch.mean(embs, dim=1)\n",
    "# print(lightgcn_out, lightgcn_out.shape, self.num_users, self.num_items)\n",
    "users, items = torch.split(lightgcn_out, [4000, 1000]) # num_users ~ num_users + num_items\n",
    "\n",
    "\n",
    "u_embedding = users\n",
    "i_embedding = items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9a1b7c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 3, 100])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "77edb6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 100])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgcn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4b55fe3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 100])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a74281c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 100])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea88f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_latent = F.embedding(user, u_embedding) # batch_users\n",
    "positive_latent = F.embedding(pos, i_embedding) # batch_pos, batch_neg\n",
    "\n",
    "positive_score = torch.mul(user_latent, positive_latent).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1e633382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1646, 0.6449, 0.1580],\n",
       "         [0.6256, 0.6581, 0.5673],\n",
       "         [0.7738, 0.3639, 0.0376],\n",
       "         [0.2759, 0.5159, 0.4110]],\n",
       "\n",
       "        [[0.1426, 0.4004, 0.0435],\n",
       "         [0.6455, 0.1574, 0.6328],\n",
       "         [0.0737, 0.5741, 0.0546],\n",
       "         [0.3497, 0.9031, 0.0952]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "# an embedding matrix containing 10 tensors of size 3\n",
    "embedding_matrix = torch.rand(10, 3)\n",
    "F.embedding(input2, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1222c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.embedding(input2, embedding_matrix).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cb2e76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a22 = F.embedding(input2, embedding_matrix)#.shape\n",
    "a33 = F.embedding(input2, embedding_matrix)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9d101a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0271, 0.4159, 0.0250],\n",
       "          [0.3914, 0.4331, 0.3219],\n",
       "          [0.5988, 0.1324, 0.0014],\n",
       "          [0.0761, 0.2661, 0.1689]],\n",
       " \n",
       "         [[0.0203, 0.1603, 0.0019],\n",
       "          [0.4166, 0.0248, 0.4004],\n",
       "          [0.0054, 0.3295, 0.0030],\n",
       "          [0.1223, 0.8156, 0.0091]]]),\n",
       " torch.Size([2, 4, 3]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(a22, a33), torch.mul(a22, a33).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "428cdf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0934, 1.2476, 0.5172],\n",
       "         [0.5647, 1.3302, 0.4143]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(a22, a33).sum(1), torch.mul(a22, a33).sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b2191f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0934, 1.2476, 0.5172],\n",
       "        [0.5647, 1.3302, 0.4143]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(a22, a33).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ [0.0271, 0.4159, 0.0250],\n",
    "  [0.3914, 0.4331, 0.3219],\n",
    "  [0.5988, 0.1324, 0.0014],\n",
    "  [0.0761, 0.2661, 0.1689]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2a5c0685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0934000000000001"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array([0.0271, 0.3914, 0.5988, 0.0761]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
